{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsQCCr8gf5f-"
      },
      "source": [
        "# Multi-Label Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4p_5UnIad1K"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from pandas.plotting import autocorrelation_plot\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDanBQdWao9J"
      },
      "source": [
        "df = pd.read_csv('C:\\Repos\\DS-3FeaturesClassification\\df_data.csv')\n",
        "df = pd.get_dummies(df,columns=['target'],prefix = ['target'])\n",
        "x = np.dstack( (np.array(df['x1']) , np.array(df['x2']), np.array(df['x3'])) )\n",
        "y = np.dstack( (np.array(df['_target'], (np.array(df['target_low']) , np.array(df['target_med']), np.array(df['target_high'])) )\n",
        "\n",
        "x = x[0,:,:]\n",
        "y = y[0,:,:]"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-110-e5665ee49ff4>, line 6)",
          "traceback": [
            "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-110-e5665ee49ff4>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    x = x[0,:,:]\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    0.6\n",
              "0    0.4\n",
              "Name: target_low, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "df['target_low'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.9\n",
              "1    0.1\n",
              "Name: target_med, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "df['target_med'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.7\n",
              "1    0.3\n",
              "Name: target_high, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "df['target_low'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "arr_dict = {0:\"low\", 1:\"med\", 2:\"high\"}\n",
        "def arr2class(_arr):\n",
        "    return arr_dict[np.argmax(_arr)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
        "true_arr = []\n",
        "for arr in y_test:\n",
        "    true_arr.append(arr2class(arr))\n",
        "\n",
        "df_pred = pd.DataFrame()\n",
        "df_pred['true'] = true_arr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6FPp9EegFWd"
      },
      "source": [
        "# Escalando dados para deep learning"
      ]
    },
    {
      "source": [
        "## Função de ativação e otimizador.\n",
        "\n",
        "Função de ativação \n",
        "\n",
        "Como convertemos os valores negativos em escalas individuais de 0 a 1 para cada feature x1,x2,x3 podemos utilizar melhor as funções de ativação compatíveis com tais valores, no caso a ReLu é apropriada para o seleção de features visto que sua derivada produz uma função degrau que irá desativar ou ativar features para cada label.\n",
        "\n",
        "### Funções de ativação:\n",
        "[<img src=\"https://4.bp.blogspot.com/-4puZ_ZMyoLE/WPk_rwqhKnI/AAAAAAAAAjU/vrNE_Uv54yMLOd_3E83PvgpByf019ufZwCLcB/s400/ActivationFunctions.png\">]\n",
        "\n",
        "[<img src=\"https://1.bp.blogspot.com/-eT7Sq-cmXSQ/WPk_r6agDnI/AAAAAAAAAjY/uWakDV5UBSw_5L0Sw53XLnogv2ExNOQRwCEw/s400/ActivationFunctionDerivatives.png\">]\n",
        "\n",
        "Otimizador para o treino backpropagation será escolhido Adam, que em comparação a outros otimizadores de reajuste de gradiente, é o que converge mais rápido!\n",
        "\n",
        "[<img src=\"https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/05/Comparison-of-Adam-to-Other-Optimization-Algorithms-Training-a-Multilayer-Perceptron.png\">]\n",
        "\n",
        "\n",
        "Fonte: Machine Learning Mastery\n",
        "https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "## Modelagem da rede.  \n",
        "Podemos modelar inicialmente a rede neural com 9 neuronios na entrada, inferindo que cada 1 das 3 saídas é uma combinação específica de 3 features x1,x2,x3 da entrada. A saída será de 3 neuronios pois teremos uma classificação binária de 3 labels high(1,0,0), low(0,1,0), med(0,0,1)\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count     2500\n",
              "unique       2\n",
              "top       True\n",
              "freq      1457\n",
              "Name: mlp1_score, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "source": [
        "current_model = 'mlp1'\n",
        "mlp1 = Sequential()\n",
        "mlp1.add(Dense(9, input_dim=3, kernel_initializer='he_uniform', activation='tanh')) #tanh para admitir entrada de valores negativos\n",
        "mlp1.add(Dense(3, activation='relu')) # saida com função degrau\n",
        "mlp1.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "mlp1.save_weights(current_model + \"_wheigts_initial.h5\")\n",
        "\n",
        "history1 = mlp1.fit(x_train, y_train, verbose=0, epochs=9)\n",
        "results1 = mlp1.predict(x_test)\n",
        "\n",
        "test_arr = []\n",
        "for arr in results1:\n",
        "    test_arr.append(arr2class(arr))\n",
        "df_pred['mlp1_predicted_class'] = test_arr\n",
        "df_pred['mlp1_score'] = np.where(df_pred[\"true\"] == df_pred[\"mlp1_predicted_class\"], True, False)\n",
        "df_pred['mlp1_score'].describe()"
      ]
    },
    {
      "source": [
        "# KNN\n",
        "\n",
        "Para este problema podemos utilizar o algoritmo popular KNN(K — Nearest Neighbors), pois é um algoritmo de treino supervisionado (e este problema temos o valor supervisionado y = \"target\" para cada entrada de treinamento)\n",
        "\n",
        "E as entradas de treino possuem valores quantitativos que podem ser interpretados como distancias euclidianas no espaço entre as features até o valor supervisionado.\n",
        "\n",
        "No exemplo abaixo, as features x1,x2,x3 poderiam ser intepretadas como Wheelbase, price in thousands e horsepower.\n",
        "\n",
        "\n",
        "[<img src=\"https://www.ibm.com/support/knowledgecenter/bs/SSLVMB_24.0.0/spss/images/images_m-r/model_knn_feature_space_cars_02.jpg\">]\n",
        "\n",
        "\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count     2500\n",
              "unique       2\n",
              "top       True\n",
              "freq      1379\n",
              "Name: knn_score, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "knn_clf=KNeighborsClassifier()\n",
        "knn_clf.fit(x_train,y_train)\n",
        "results2 = knn_clf.predict(x_test)\n",
        "\n",
        "test_arr = []\n",
        "for arr in results2:\n",
        "    test_arr.append(arr2class(arr))\n",
        "df_pred['knn_predicted_class'] = test_arr\n",
        "df_pred['knn_score'] = np.where(df_pred[\"true\"] == df_pred[\"knn_predicted_class\"], True, False)\n",
        "df_pred['knn_score'].describe()"
      ]
    },
    {
      "source": [
        "# COMPARANDO"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n\n     MLP \n\n True     0.5828\nFalse    0.4172\nName: mlp1_score, dtype: float64\n\n\n     KNN \n\n True     0.5516\nFalse    0.4484\nName: knn_score, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\\n     MLP \\n\\n\", df_pred['mlp1_score'].value_counts(normalize=True))\n",
        "print(\"\\n\\n     KNN \\n\\n\", df_pred['knn_score'].value_counts(normalize=True))"
      ]
    },
    {
      "source": [
        "# REDE NEURAL ACERTOU 58,28% E KNN 55,16%"
      ],
      "cell_type": "markdown",
      "metadata": {}
    }
  ]
}